{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466ab9ca-0a41-4ca7-91ea-b7e7559b256c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load input datasets\n",
    "customers_df = spark.read.csv(\"/Volumes/workspace/default/bronze/customers.csv\", header=True, inferSchema=True)\n",
    "claims_df = spark.read.csv(\"/Volumes/workspace/default/bronze/claims.csv\",header=True,inferSchema=True)\n",
    "\n",
    "\n",
    "customers_df.display()\n",
    "\n",
    "claims_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16126c9a-ca6a-4f46-9309-dd3e734b2e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Quality & Integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8694f0f-c403-43e8-b0d3-523a59a37f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finding Duplicates and Deduplicate duplicate claims. \n",
    "from pyspark.sql.functions import *\n",
    "customers_dup = customers_df.groupBy(\"customer_id\",\"name\", \"city\", \"state\").count().filter(col(\"count\") > 1).show()\n",
    "customers_dup = claims_df.groupBy(\"claim_amount\",\"insured_amount\", \"hospital_name\", \"state\").count().filter(col(\"count\") > 1).show()\n",
    "\n",
    "#  customers_drop = customers_df.dropna()\n",
    "#  claims_drop = claims_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871f3ba7-ecfb-4d9d-8673-d625fad8741e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finding Null Values , Handle null values appropriately. \n",
    "customers_df.filter(customers_df.name.isNull()).show()\n",
    "claims_df.filter(claims_df.claim_amount.isNull()).show()\n",
    "# df_filled = customers_df.fillna({\"city\": 0, \"name\": \"Unknown\"})\n",
    "# df_filled = claims_df.fillna({\"claim_amount\": 0, \"hospital_name\": \"Unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cecb4796-7396-45bb-989c-2fa9e78bc5e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_df.printSchema()\n",
    "claims_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3357c2-94b8-455c-af6a-04e08664ffea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Validate column data types (e.g., numeric fields must be numeric).\n",
    "# customers_df = customers_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"double\")).show()\n",
    "# claims_df = claims_df.withColumn(\"claim_amount\", col(\"claim_amount\").cast(\"double\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de8f7ea-07f7-411f-ae2d-7b8c576f6636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Silver dataset storage after cleaning data\n",
    "customers_df.write.format(\"parquet\").mode(\"overwrite\").save(\"/Volumes/workspace/default/Silver_Dataset\")\n",
    "claims_df.write.format(\"parquet\").mode(\"overwrite\").save(\"/Volumes/workspace/default/Silver_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c132728-f554-4d0d-a728-2c106a1f8dbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading data from Silver \n",
    "customers_df1 = spark.read.parquet(\"/Volumes/workspace/default/Silver_Dataset\", header=True, inferSchema=True)\n",
    "claims_df1 = spark.read.parquet(\"/Volumes/workspace/default/Silver_Dataset\",header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9522cb21-8f24-4644-ae24-1f2d0796f0a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count, countDistinct, year, weekofyear, lit, unix_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Convert claim_date to numeric (seconds) for Rule 2\n",
    "df = claims_df1.withColumn(\"claim_ts\", unix_timestamp(\"claim_date\"))\n",
    "\n",
    "# --------------------\n",
    "# Rule 1: Invalid Claim\n",
    "# --------------------\n",
    "df = df.withColumn(\n",
    "    \"rule1_invalid\",\n",
    "    when(col(\"claim_amount\") > col(\"insured_amount\"), lit(1)).otherwise(lit(0))\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Rule 2: More than 3 claims in 30 days\n",
    "# --------------------\n",
    "window_30d = Window.partitionBy(\"customer_id\").orderBy(\"claim_ts\").rangeBetween(-30*86400, 0)\n",
    "\n",
    "df = df.withColumn(\"claims_last_30_days\", count(\"claim_id\").over(window_30d)) \\\n",
    "       .withColumn(\"rule2_suspicious\", when(col(\"claims_last_30_days\") > 3, lit(1)).otherwise(lit(0)))\n",
    "\n",
    "# --------------------\n",
    "# Rule 3: Different states within same week\n",
    "# --------------------\n",
    "df = df.withColumn(\"year\", year(\"claim_date\")) \\\n",
    "       .withColumn(\"week\", weekofyear(\"claim_date\"))\n",
    "\n",
    "state_counts = df.groupBy(\"customer_id\", \"year\", \"week\") \\\n",
    "    .agg(countDistinct(\"state\").alias(\"distinct_states\"))\n",
    "\n",
    "# Do a SAFE join (preserve all existing df columns)\n",
    "df = df.alias(\"main\").join(\n",
    "    state_counts.alias(\"agg\"),\n",
    "    on=[\"customer_id\",\"year\",\"week\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"rule3_suspicious\", when(col(\"distinct_states\") > 1, lit(1)).otherwise(lit(0)))\n",
    "\n",
    "# --------------------\n",
    "# Final Fraud Status\n",
    "# --------------------\n",
    "df = df.withColumn(\n",
    "    \"fraud_status\",\n",
    "    when(col(\"rule1_invalid\") == 1, lit(\"Invalid\"))\n",
    "     .when((col(\"rule2_suspicious\") == 1) | (col(\"rule3_suspicious\") == 1), lit(\"Suspicious\"))\n",
    "     .otherwise(lit(\"Valid\"))\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Final Select\n",
    "# --------------------\n",
    "df.select(\n",
    "    \"claim_id\",\"customer_id\",\"claim_date\",\"claim_amount\",\"insured_amount\",\n",
    "    \"state\",\"rule1_invalid\",\"rule2_suspicious\",\"rule3_suspicious\",\"fraud_status\"\n",
    ").show(20, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48143b7d-3d05-4427-822a-7c0f13b7230d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold dataset storage after Performing some agg pe\n",
    "customers_df.write.format(\"parquet\").mode(\"overwrite\").save(\"/Volumes/workspace/default/Gold_Dataset\")\n",
    "df_cleaned.write.format(\"parquet\").mode(\"overwrite\").save(\"/Volumes/workspace/default/Gold_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75c91ef-2845-40fe-b2cb-9330186c4b94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 5 customers with the most suspicious claims\n",
    "df_cleaned.createOrReplaceTempView(\"claims\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT customer_id,\n",
    "       COUNT(*) AS suspicious_claims\n",
    "FROM claims\n",
    "WHERE fraud_status = 'Suspicious'\n",
    "GROUP BY customer_id\n",
    "ORDER BY suspicious_claims DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b871f9ed-e688-4b6d-b163-0a58f1259d42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# States with the highest suspicious claim ratio\n",
    "spark.sql(\"\"\"\n",
    "SELECT state,\n",
    "       SUM(CASE WHEN fraud_status = 'Suspicious' THEN 1 ELSE 0 END) * 1.0 / COUNT(*) AS suspicious_ratio,\n",
    "       COUNT(*) AS total_claims\n",
    "FROM claims\n",
    "GROUP BY state\n",
    "ORDER BY suspicious_ratio DESC\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f22c242-691c-4a9e-a1f8-9be9012f1f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Average insured vs. claim amount for Valid vs. Suspicious claims\n",
    "spark.sql(\"\"\"\n",
    "SELECT fraud_status,\n",
    "       AVG(insured_amount) AS avg_insured_amount,\n",
    "       AVG(claim_amount)   AS avg_claim_amount,\n",
    "       COUNT(*) AS total_claims\n",
    "FROM claims\n",
    "WHERE fraud_status IN ('Valid','Suspicious')\n",
    "GROUP BY fraud_status\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44a3b133-5437-45fa-9044-a0c8c4d6941c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = claims_df.withColumn(\"claim_ts\", unix_timestamp(\"claim_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b793e4-82c2-4757-a378-3ed8ab524b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Keeps only claims where customer exists.\n",
    "valid_claims = claims_df.join(customers_df, \"customer_id\", \"inner\")\n",
    "valid_claims.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a18b12-4b8b-4362-9c25-4127d95053f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Find claims with no matching customer\n",
    "invalid_claims = claims_df.join(customers_df, \"customer_id\", \"left_anti\")\n",
    "invalid_claims.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8892094830294376,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Backup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
